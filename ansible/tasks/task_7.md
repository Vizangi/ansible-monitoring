# Ansible + Terraform

## **Task 7**

_Для подобного рода задач заводится таска в Jira (вкратце в описании описывается план проведения работ, выставляется время проведения работ, указывается исполнитель и ответственный), прикладывается документация в формате `.docx`, где прописано построчно, что будет происходить, и что делать в случае сбоя (откат). То есть вот вам еще одна строчка в резюме - придумайте, как её красиво расписать._

### Разворачивание глобальной инфраструктуры мониторинга на проекте

- Нужно написать Terraform IaC темплейт для раворачивания x14 пустых контейнеров Docker с ОС Debian (помним, что это VM-ки), как по репозиторию Terraform.
 - Тут нужно будет подумать сколько ресурсов дать каждому контейнеру (это важно для ПРОД контуров и вообще для рационального распределения ресурсов):
   ```bash
   resource "docker_container" "empty_debian_container" {
     count = 5
   
     name  = "debian-container-${count.index}"
     image = docker_image.debian.image_id
     must_run = true
     command = ["tail", "-f", "/dev/null"]
   
     # Пример установки лимитов (добавьте эти строки при необходимости):
     memory      = 128 # Лимит ОЗУ в мегабайтах (например, 128MB)
     memory_swap = 256 # Лимит ОЗУ + Swap в мегабайтах
     cpus        = "0.5" # Лимит ЦП (например, 0.5 ядра)
     cpu_shares  = 512 # Относительный вес ЦП (по умолчанию 1024)
   }
   ```
- Используем одну VM, как основную для задания, сколько выдать ресурсов подумайте сами. 
- Раскатку экспортеров делаем в вакууме, так как у нас нет времени отдельно поднимать: Nginx, Kafka и БД (с соответствующими настройками, но это и не нужно, так как на работе серверы уже будут установлены и на них нужно будет накатывать экспортеры), то есть ставим экспортеры в пустые контейнеры и получаем с них метрики, для нас здесь важно понимание принципа работы Ansible с IaC.
- В данном задании нужно подумать, как раскатать 14 контейнеров, в составе которых будет `openssh` - можно собрать индивидуальный Dockerfile и раскатать через Docker Compose 14 контейнеров.
- Далее идем в Ansible и пишем роли для экспортеров ниже.

### Архитектура:

  **Основной мониторинг:**
  - Раскатываем на этой же вируталке Docker Compose: Grafana + Prometheus (вне роли). 

  **Системный мониторинг и прочее:**
  
  1. **Node Exporter:** Сбор метрик ОС и железа для Linux/UNIX. Крайне важен для базового мониторинга серверов.
  2. **Blackbox Exporter:** "Черноящичный" мониторинг доступности внешних эндпоинтов (HTTP, DNS, TCP, ICMP).
  3. **JMX Exporter:** Сбор метрик с Java-приложений, использующих JMX. Очень универсален для Java-стека.
  4. **SNMP Exporter:** Позволяет собирать метрики с устройств, поддерживающих протокол SNMP. Широко используется для сетевого оборудования.
  5. **Pushgateway:** Используется в связке с экспортерами для сбора метрик с короткоживущих или периодически запускаемых задач, которые не могут быть постоянно опрашиваемы Prometheus.
  
  **Базы данных:**
  
  6.  **MySQLd Exporter:** Мониторинг серверов MySQL и MariaDB.
  7.  **Postgres Exporter:** Мониторинг баз данных PostgreSQL.
  8.  **MongoDB Exporter:** Мониторинг серверов MongoDB.
  9.  **Redis Exporter:** Мониторинг Redis key-value store.
  
  **Веб-серверы и прокси:**
  
  10. **Nginx Exporter:** Сбор метрик с веб-сервера Nginx.
  11. **Apache Exporter:** Сбор метрик с Apache HTTP Server.
  12. **HAProxy Exporter:** Мониторинг балансировщика нагрузки HAProxy.
  
  **Системы очередей сообщений:**
  
  13. **RabbitMQ Exporter:** Мониторинг RabbitMQ.
  14. **Kafka Exporter:** Мониторинг брокеров Kafka и потребительских групп.

Этот список охватывает основные категории систем, которые часто требуют мониторинга.

- Далее раскатываем Ansible-roles с экспортерами на 14 пустых контейнеров Debian (VM).
  - Тут нужно будет подумать, как Ansible будет определять на какие контейнеры катать, если контейнеры были раскатаны рандомно?
- После успешной раскатки экспортеров на них, проверьте эндпоинты Prometheus по `remote-read` по всем контейнерам.
- Воспроизведите все официальные дашборды для проверки (если работают не все, то ничего страшного, на данном этапе важно, чтобы Prometheus видел все endpoints).
- Сохраните изменения в GitHub репозиторий.
